{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f60e6b1",
   "metadata": {},
   "source": [
    "# Time Skew Testing\n",
    "\n",
    "This animation system allows a user to define a frame and how long they would like that frame to be displayed for.\n",
    "This only works if the ability to display frames is instantaneous. This, however, is not true. It takes time to loop through each pixel and set it's value. It also takes time to communicate those pixel values to the LED strand. This time should be measured and accounted for.\n",
    "\n",
    "Imagine for a moment that we have an animation that is `FILL ME IN` frames long and that each frame is displayed for `FILL ME IN` ms. In a perfect system, this animation would display for 1`FILL ME IN` ms or `FILL ME IN` seconds, or `FILL ME IN`, which is considerably short. When we have a large number of short frames, it's possible that the communication latency is enought to become visibly noticlable. If we pretend that it takes 1 ms per render, this adds 10% to the length of our animation, which was not expected or accounted for, making it difficult to accurately time frames. Furthermore, this value changes from system to system.\n",
    "\n",
    "The purpose of this notebook is to:\n",
    "- Write a test for development purposed (or for those using this library what want to do their own testing).\n",
    "- Experiment with ways to calculte these things."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d879cba",
   "metadata": {},
   "source": [
    "## Different Timing Functions\n",
    "\n",
    "At some point, we need a way to measure the passage of time. We want something that:\n",
    "- Has high accuracy (ns would be nice)\n",
    "- Is monotonic (it always goes forward; we don't care about time changes or TZs or daylight savings time)\n",
    "\n",
    "The Python standard library has a few options that immediately come to mind:\n",
    "- [time.monotonic_ns()](https://docs.python.org/3/library/time.html#time.monotonic_ns)\n",
    "- [time.perf_counter_ns()](https://docs.python.org/3/library/time.html#time.perf_counter_ns)\n",
    "\n",
    "Looking at those descriptions, the only noteable thing that is brought up is accounting for `sleep()`. Aside from that, there is no obvious reason to choose one over the other. Since `perf_counter_ns` seems to be named to imply that it's for measureing performance, I'll start with that one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1c4c68",
   "metadata": {},
   "source": [
    "## Generic Testing Function\n",
    "\n",
    "To run several different tests, we'll generate a generic testing function. This function will take:\n",
    "- The number of pixels\n",
    "- The number of frames\n",
    "- The delay for each frame\n",
    "- Something to send the pixels to\n",
    "\n",
    "It will return multiple `List`s containing timings to be crunched later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c091a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "from adafruit_dotstar_pi_animation.data import *\n",
    "\n",
    "def generate_random_color() -> int:\n",
    "    return random.randrange(8) * 32\n",
    "\n",
    "\n",
    "def generate_test_animation(pixel_count: int, frame_count: int, frame_delay: int) -> (int, Animation):\n",
    "    \"\"\"\n",
    "    This function generates and times how long it takes to generate said test animation.\n",
    "    \"\"\"\n",
    "    \n",
    "    generation_start = time.perf_counter_ns()\n",
    "    frames = []\n",
    "    # For each frame:\n",
    "    for f_idx in range(frame_count):\n",
    "        pixels = []\n",
    "        # for each pixel:\n",
    "        for p_idx in range(pixel_count):\n",
    "            pixel = Pixel(red=generate_random_color(), blue=generate_random_color(), green=generate_random_color(), brightness=1.0)\n",
    "            pixels.append(pixel)\n",
    "            \n",
    "        frame = Frame(pixels=pixels, display_ms=frame_delay)\n",
    "        frames.append(frame)\n",
    "        \n",
    "    animation = Animation(frames=frames, loop_infinitely=False, pause_between_play_ms=0, max_plays=1)\n",
    "    generation_end = time.perf_counter_ns()\n",
    "    \n",
    "    return generation_end - generation_start, animation\n",
    "\n",
    "\n",
    "def test_drawing_a(dot_star, animation: Animation) -> (List[int], List[int]):\n",
    "    \"\"\"\n",
    "    This test handles instrumenting the \"alpha\" algorithm.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # Play Algo that we're testing\n",
    "    ##############################\n",
    "    parsing_ts = []\n",
    "    tx_ts = []\n",
    "    \n",
    "    loop_count = 0\n",
    "    while True:\n",
    "        \n",
    "        for frame_idx, frame in enumerate(animation.frames):\n",
    "            # Loops the frames\n",
    "\n",
    "            for pixel_idx, pixel in enumerate(frame.pixels):\n",
    "                # Loops the pixels\n",
    "                parsing_ts.append(time.perf_counter_ns())\n",
    "                dot_star[pixel_idx] = (pixel.red, pixel.blue, pixel.green, pixel.brightness)\n",
    "                parsing_ts.append(time.perf_counter_ns())\n",
    "\n",
    "            # Show the frame for a while\n",
    "            tx_ts.append(time.perf_counter_ns())\n",
    "            dot_star.show()\n",
    "            tx_ts.append(time.perf_counter_ns())\n",
    "            \n",
    "            time.sleep(frame.display_ms / 1000)\n",
    "\n",
    "        loop_count += 1\n",
    "        if loop_count >= animation.max_plays:\n",
    "            break\n",
    "            \n",
    "    return parsing_ts, tx_ts\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b0679f",
   "metadata": {},
   "source": [
    "First test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786c2cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import adafruit_dotstar\n",
    "import board\n",
    "\n",
    "\n",
    "num_leds = 11\n",
    "pixels = adafruit_dotstar.DotStar(board.SCLK, board.MOSI, num_leds, pixel_order=adafruit_dotstar.BGR, auto_write=False)\n",
    "animation_generation_ns, animation = generate_test_animation(11, 10000, 10)\n",
    "start_time = time.perf_counter_ns()\n",
    "parse_timings, tx_timings = test_drawing_a(pixels, animation)\n",
    "end_time = time.perf_counter_ns()\n",
    "\n",
    "print(f'Total play time in ns: {end_time - start_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92200cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_timing_pairs(timings):\n",
    "    differences = []\n",
    "    \n",
    "    start_time = None\n",
    "    for t in timings:\n",
    "        if start_time is None:\n",
    "            start_time = t\n",
    "        else:\n",
    "            differences.append(t - start_time)\n",
    "            start_time = None\n",
    "            \n",
    "    return differences\n",
    "        \n",
    "\n",
    "parse_timing_differences = process_timing_pairs(parse_timings)\n",
    "tx_timming_differences = process_timing_pairs(tx_timings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9e7116",
   "metadata": {},
   "source": [
    "Some basic numbers:\n",
    "- How long did we expect the animation to take?\n",
    "- How long did it actually take?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57063da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "play_time_expected_seconds = animation.frame_total_time_ms / 1000\n",
    "actual_play_time_seconds = (end_time - start_time) / 1000000000\n",
    "\n",
    "play_time_expected_seconds, actual_play_time_seconds, abs(play_time_expected_seconds-actual_play_time_seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c06a43",
   "metadata": {},
   "source": [
    "Wow, that's 11.7 seconds slower. That's much larger than I was expecting. Let's see if we can completely account for that time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b5de79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "\n",
    "time_lost_in_parsing = reduce(lambda x, y: x + y, parse_timing_differences)\n",
    "time_lost_in_tx = reduce(lambda x, y: x + y, tx_timming_differences)\n",
    "\n",
    "total_time_lost_ns = time_lost_in_parsing + time_lost_in_tx\n",
    "total_time_lost_ns / 1000000000, time_lost_in_parsing / 1000000000, time_lost_in_tx / 1000000000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1750a01b",
   "metadata": {},
   "source": [
    "We can account for about 10 seconds of loss. Some of the additional loss might stem from:\n",
    "- Our instrumentation efforts\n",
    "- Inaccuracies in `time.sleep()`\n",
    "- Other processes contending for time on this machine\n",
    "\n",
    "TO be 1.7 seconds off over the course of 100 seconds isn't super significant, but it would be nice to study this further and to try to develop an algorithm that can correct and speed up or drop frames to catch up when it's slow.\n",
    "\n",
    "What is the average time to parse all 11 pixels and to send them down the wire (in ms)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee70ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "\n",
    "\n",
    "mean_parsing_time_per_pixel = statistics.mean(parse_timing_differences)\n",
    "mean_tx_time_per_frame = statistics.mean(tx_timming_differences)\n",
    "\n",
    "mean_parsing_time_per_pixel, mean_tx_time_per_frame, mean_tx_time_per_frame / num_leds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c5f5cb",
   "metadata": {},
   "source": [
    "There is 0.04 ms delay for each pixel parsed and then an additional 0.04 ms delay for each one pushed down the wire. One would think these things scale linearly.\n",
    "\n",
    "A 10 ms delay between frames is pretty high. That's 100hz, which is faster than the average TV. Let's lower this to 10hz and see if our numbers stay roughly the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07f0014",
   "metadata": {},
   "outputs": [],
   "source": [
    "animation_generation_ns, animation = generate_test_animation(11, 1000, 100)\n",
    "start_time = time.perf_counter_ns()\n",
    "parse_timings, tx_timings = test_drawing_a(pixels, animation)\n",
    "end_time = time.perf_counter_ns()\n",
    "\n",
    "print(f'Total play time in ns: {end_time - start_time}')\n",
    "\n",
    "parse_timing_differences = process_timing_pairs(parse_timings)\n",
    "tx_timming_differences = process_timing_pairs(tx_timings)\n",
    "play_time_ns = end_time - start_time\n",
    "expected_play_time_ns = animation.frame_total_time_ms * 1000000\n",
    "\n",
    "time_lost_in_parsing = reduce(lambda x, y: x + y, parse_timing_differences)\n",
    "time_lost_in_tx = reduce(lambda x, y: x + y, tx_timming_differences)\n",
    "total_time_lost_ns = abs(play_time_ns - expected_play_time_ns)\n",
    "print(f'Time lost in parsing: {time_lost_in_parsing/1000000000}')\n",
    "print(f'Time lost in txt: {time_lost_in_tx/1000000000}')\n",
    "print(f'Time lost total: {total_time_lost_ns/1000000000}')\n",
    "print(f'Unaccounted lost time: {(total_time_lost_ns - time_lost_in_tx - time_lost_in_parsing)/1000000000}')\n",
    "\n",
    "\n",
    "mean_parsing_time_per_pixel = statistics.mean(parse_timing_differences)\n",
    "mean_tx_time_per_frame = statistics.mean(tx_timming_differences)\n",
    "print(f'Mean parsing time per pixel: {mean_parsing_time_per_pixel}')\n",
    "print(f'Mean tx time per pixel: {mean_tx_time_per_frame/num_leds}')\n",
    "\n",
    "pixels.fill((0, 0, 0))\n",
    "pixels.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4637d40a",
   "metadata": {},
   "source": [
    "Even with this reduced play rate, we lose a considerable amount of time (>1%), about 20% of which is not accounted for."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd48c68",
   "metadata": {},
   "source": [
    "## Time Drift Correction\n",
    "\n",
    "Imagine that at the start of every frame, we took note of the time. We could display each frame for the duration of `display_ms - parsing time - tx time`. This helps us, but does not account for `time.sleep()` also being inaccurate. We need to somehow track time drift across all frames. Another possible solution is to play the first frame, redcord it's total time, and display the next frame for that much less time. This allows the next frame to correct for the first. The third frame could do this for the first frame and so on. This has the advantage of tracking the drift at any point in time. It also gives the the ability to drop a frame if we know that we're `x` time behind and the next frame is `y` time where `x < y`. We could make this even more sophisticated by developing a quick (<10ms) way to test how long it takes to parse-n-push data to the LEDs, allowing us to take this into account, too. The hard part will be the math around dropping frames and resuming correct time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719f1faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_drawing_b(dot_star, animation: Animation, frames_per_adjustment=10, drift_threshold_ms=25) -> (List[int], List[int]):\n",
    "    \"\"\"\n",
    "    This test handles instrumenting the \"alpha\" algorithm.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # Play Algo that we're testing\n",
    "    ##############################\n",
    "    total_drift_ns = 0\n",
    "    \n",
    "    loop_count = 0\n",
    "    adjustments = []\n",
    "    while True:\n",
    "        \n",
    "        last_frame_start = time.perf_counter_ns()\n",
    "        for frame_idx, frame in enumerate(animation.frames):\n",
    "            # Loops the frames\n",
    "            \n",
    "            show_adjustment_ns = 0\n",
    "            \n",
    "            for pixel_idx, pixel in enumerate(frame.pixels):\n",
    "                # Loops the pixels\n",
    "                dot_star[pixel_idx] = (pixel.red, pixel.blue, pixel.green, pixel.brightness)\n",
    "\n",
    "            # Show the frame for a while\n",
    "            dot_star.show()\n",
    "            \n",
    "            # Do we need to adjust with some sort of correction?\n",
    "            if frame_idx % frames_per_adjustment == 0:\n",
    "                # Check for the need to correct\n",
    "                if total_drift_ns > drift_threshold_ms * 1000000:\n",
    "                    show_adjustment_ns = min(max(total_drift_ns / 2, frame.display_ms * 1000000 / 2), frame.display_ms * 1000000)\n",
    "            # Account for analysis after\n",
    "            adjustments.append((frame_idx, total_drift_ns, show_adjustment_ns))\n",
    "                \n",
    "            # Let the frame stand for a bit\n",
    "            time_to_show_sec = (frame.display_ms / 1000) - (show_adjustment_ns / 1000000000)\n",
    "            time.sleep(time_to_show_sec)\n",
    "            \n",
    "            # Use a third value to allow timers to overlap\n",
    "            end_show = time.perf_counter_ns()\n",
    "            current_frame_start = end_show\n",
    "            \n",
    "            # Drif accounting\n",
    "            actual_display_time_ns = end_show - last_frame_start\n",
    "            frame_display_ns = frame.display_ms * 1000000\n",
    "            frame_drift_ns = actual_display_time_ns - frame_display_ns\n",
    "            total_drift_ns = total_drift_ns + frame_drift_ns\n",
    "            \n",
    "            last_frame_start = current_frame_start\n",
    "\n",
    "        loop_count += 1\n",
    "        if loop_count >= animation.max_plays:\n",
    "            break\n",
    "            \n",
    "    return adjustments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a343be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "animation_generation_ns, animation = generate_test_animation(11, 1000, 100)\n",
    "start_time = time.perf_counter_ns()\n",
    "adjustments = test_drawing_b(pixels, animation)\n",
    "end_time = time.perf_counter_ns()\n",
    "\n",
    "print(f'Total play time in ns: {end_time - start_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ab3d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjustments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d427c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixels.fill((0, 0, 0))\n",
    "pixels.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
